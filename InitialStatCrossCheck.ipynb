{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdjDRBK/q6K+yAZDnfb0aT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanCP26/nbaPredictor/blob/main/InitialStatCrossCheck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_PBfKP9jgtN",
        "outputId": "bf485134-4064-41c1-f8ea-7cb368ac7dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working dir: /content\n",
            "Files (first 40): .config, .ipynb_checkpoints, drive, injury_stats_24_25.csv, player_injury_risk_scores_24_25.csv, player_season_24_25_with_injury_score.csv, sample_data, test, train\n",
            "\n",
            "Using files (FOR TRAINING):\n",
            " injury     = injury_stats_24_25.csv\n",
            " box_out    = train/Box Out Statistics - Sheet1.csv\n",
            " hustle     = train/Hustle Statistics - Sheet1.csv\n",
            " general    = train/General + drives - Sheet1 (1).csv\n",
            " shot_sel   = train/Shot Selection Stats - Sheet2.csv\n",
            "\n",
            "Ranking evaluation (predicting injury burden):\n",
            " Spearman rho(pred, true injury_score): 0.7294 (p=9.04e-128)\n",
            " Top 10% avg injury_score: 37.122\n",
            " Overall avg injury_score: 12.413\n",
            " Top-10% lift: 2.990x\n",
            " AUC for injury_score >= 1: 0.8912 (positives=444)\n",
            " AUC for injury_score >= 3: 0.8871 (positives=384)\n",
            " AUC for injury_score >= 5: 0.8848 (positives=358)\n",
            " AUC for injury_score >= 8: 0.8892 (positives=299)\n",
            "\n",
            "Saved:\n",
            " player_season_24_25_with_injury_score.csv\n",
            " player_injury_risk_scores_24_25.csv\n"
          ]
        }
      ],
      "source": [
        "import os, glob, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "try:\n",
        "    from scipy.stats import spearmanr\n",
        "    HAVE_SCIPY = True\n",
        "except Exception:\n",
        "    HAVE_SCIPY = False\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Logging\n",
        "# =========================\n",
        "def log(msg):\n",
        "    print(msg)\n",
        "\n",
        "def safe_listdir(path=\".\"):\n",
        "    try:\n",
        "        return sorted(os.listdir(path))\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "# =========================\n",
        "# File discovery (FIXED)\n",
        "#   - Prefer 24-25\n",
        "#   - Exclude 2016-17 and 2016_17\n",
        "# =========================\n",
        "def is_bad_file(path: str) -> bool:\n",
        "    p = os.path.basename(path).lower()\n",
        "    return (\"2016-17\" in p) or (\"2016_17\" in p) or (\"2016\" in p)\n",
        "\n",
        "def find_best(patterns, prefer_tokens=None, require_tokens=None):\n",
        "    \"\"\"\n",
        "    Find best matching file across patterns.\n",
        "    - Filters out 2016 files\n",
        "    - If prefer_tokens given, scores higher for those\n",
        "    - If require_tokens given, only keeps files containing all require tokens\n",
        "    \"\"\"\n",
        "    hits = []\n",
        "    for pat in patterns:\n",
        "        hits.extend(glob.glob(pat, recursive=True))\n",
        "\n",
        "    hits = [h for h in hits if os.path.isfile(h)]\n",
        "    hits = [h for h in hits if not is_bad_file(h)]\n",
        "\n",
        "    if require_tokens:\n",
        "        req = [t.lower() for t in require_tokens]\n",
        "        hits = [h for h in hits if all(t in os.path.basename(h).lower() for t in req)]\n",
        "\n",
        "    if not hits:\n",
        "        return None\n",
        "\n",
        "    def score(h):\n",
        "        name = os.path.basename(h).lower()\n",
        "        s = 0\n",
        "        if prefer_tokens:\n",
        "            for t in prefer_tokens:\n",
        "                if t.lower() in name:\n",
        "                    s += 10\n",
        "        # shorter path/name tie-breaker\n",
        "        s -= 0.001 * len(h)\n",
        "        return s\n",
        "\n",
        "    hits = sorted(hits, key=lambda h: (-score(h), len(h), h))\n",
        "    return hits[0]\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Robust column utilities\n",
        "# =========================\n",
        "def normalize_cols(df):\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns.astype(str)\n",
        "        .str.replace(\"\\n\", \" \", regex=False)\n",
        "        .str.replace(\"%\", \"PCT\", regex=False)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def make_unique_columns(df):\n",
        "    cols = list(df.columns)\n",
        "    seen = {}\n",
        "    new_cols = []\n",
        "    for c in cols:\n",
        "        if c not in seen:\n",
        "            seen[c] = 1\n",
        "            new_cols.append(c)\n",
        "        else:\n",
        "            seen[c] += 1\n",
        "            new_cols.append(f\"{c}__{seen[c]}\")\n",
        "    df = df.copy()\n",
        "    df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "# =========================\n",
        "# Player name helpers\n",
        "# =========================\n",
        "def clean_player_name(s):\n",
        "    return (\n",
        "        s.astype(str)\n",
        "        .str.replace(\"\\u00a0\", \" \", regex=False)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "\n",
        "def last_first_to_first_last(name):\n",
        "    if not isinstance(name, str):\n",
        "        name = str(name)\n",
        "    if \",\" in name:\n",
        "        last, first = [x.strip() for x in name.split(\",\", 1)]\n",
        "        return f\"{first} {last}\".strip()\n",
        "    return name.strip()\n",
        "\n",
        "def canonical_name_series(s):\n",
        "    s = clean_player_name(s).str.lower()\n",
        "    s = s.str.replace(r\"[.\\']\", \"\", regex=True)\n",
        "    s = s.str.replace(\",\", \"\", regex=False)\n",
        "    s = s.str.replace(r\"\\b(jr|sr|ii|iii|iv)\\b\", \"\", regex=True)\n",
        "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "    return s\n",
        "\n",
        "# =========================\n",
        "# Safe read\n",
        "# =========================\n",
        "def safe_read_csv(path):\n",
        "    if path is None:\n",
        "        return None\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        df = normalize_cols(df)\n",
        "        df = make_unique_columns(df)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] Could not read CSV '{path}': {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# Player/team column detection\n",
        "# =========================\n",
        "def ensure_player_col(df, filename=\"(unknown)\"):\n",
        "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        log(f\"[warn] Empty/missing dataframe for {filename}. Skipping.\")\n",
        "        return None\n",
        "\n",
        "    df = normalize_cols(df)\n",
        "    df = make_unique_columns(df)\n",
        "\n",
        "    for c in list(df.columns):\n",
        "        if c.strip().lower() in [\"player\", \"player_name\", \"player name\", \"name\", \"playerfullname\", \"player_full_name\", \"player full name\"]:\n",
        "            df = df.rename(columns={c: \"Player\"})\n",
        "            break\n",
        "\n",
        "    if \"PLAYER\" in df.columns and \"Player\" not in df.columns:\n",
        "        df = df.rename(columns={\"PLAYER\": \"Player\"})\n",
        "\n",
        "    if \"Player\" not in df.columns:\n",
        "        obj_cols = [c for c in df.columns if pd.api.types.is_object_dtype(df[c])]\n",
        "        if obj_cols:\n",
        "            df = df.rename(columns={obj_cols[0]: \"Player\"})\n",
        "            log(f\"[warn] No explicit player column in {filename}. Using '{obj_cols[0]}' as Player.\")\n",
        "        else:\n",
        "            log(f\"[warn] Could not find player column in {filename}. Columns={df.columns.tolist()[:30]}\")\n",
        "            return None\n",
        "\n",
        "    df[\"Player\"] = clean_player_name(df[\"Player\"])\n",
        "    return df\n",
        "\n",
        "def ensure_team_col(df):\n",
        "    if df is None:\n",
        "        return None\n",
        "    df = df.copy()\n",
        "    if \"TEAM\" in df.columns and \"Team\" not in df.columns:\n",
        "        df = df.rename(columns={\"TEAM\": \"Team\"})\n",
        "    if \"Team\" not in df.columns:\n",
        "        for c in list(df.columns):\n",
        "            if c.strip().lower() in [\"team\", \"tm\", \"team_abbreviation\"]:\n",
        "                df = df.rename(columns={c: \"Team\"})\n",
        "                break\n",
        "    return df\n",
        "\n",
        "# =========================\n",
        "# Collapse traded players (safe)\n",
        "# =========================\n",
        "def collapse_traded_players(df, weight_col=\"GP\"):\n",
        "    if df is None or \"Player\" not in df.columns:\n",
        "        return df\n",
        "    try:\n",
        "        df = df.copy()\n",
        "        df = ensure_team_col(df)\n",
        "        df = make_unique_columns(df)\n",
        "\n",
        "        if \"Team\" in df.columns:\n",
        "            tot_mask = df[\"Team\"].astype(str).str.upper().eq(\"TOT\")\n",
        "            players_with_tot = set(df.loc[tot_mask, \"Player\"].unique())\n",
        "            if players_with_tot:\n",
        "                df = pd.concat([\n",
        "                    df[df[\"Player\"].isin(players_with_tot) & tot_mask],\n",
        "                    df[~df[\"Player\"].isin(players_with_tot)]\n",
        "                ], ignore_index=True)\n",
        "\n",
        "        if df[\"Player\"].nunique() == len(df):\n",
        "            return df\n",
        "\n",
        "        if weight_col in df.columns:\n",
        "            w = pd.to_numeric(df[weight_col], errors=\"coerce\").fillna(1.0).values\n",
        "        else:\n",
        "            w = np.ones(len(df))\n",
        "        df[\"_w_\"] = w\n",
        "\n",
        "        for c in df.columns:\n",
        "            if c in [\"Player\", \"Team\", \"_w_\"]:\n",
        "                continue\n",
        "            if pd.api.types.is_object_dtype(df[c]):\n",
        "                tmp = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "                if tmp.notna().sum() > 0:\n",
        "                    df[c] = tmp\n",
        "\n",
        "        num_cols = [c for c in df.columns if c not in [\"Player\",\"Team\",\"_w_\"] and pd.api.types.is_numeric_dtype(df[c])]\n",
        "        other_cols = [c for c in df.columns if c not in num_cols + [\"_w_\"]]\n",
        "\n",
        "        def wavg(x):\n",
        "            x = pd.to_numeric(x, errors=\"coerce\")\n",
        "            ww = df.loc[x.index, \"_w_\"].values\n",
        "            mask = ~x.isna()\n",
        "            if mask.sum() == 0:\n",
        "                return np.nan\n",
        "            return np.average(x[mask], weights=ww[mask])\n",
        "\n",
        "        g = df.groupby(\"Player\", as_index=False)\n",
        "        agg_other = g[other_cols].first() if other_cols else pd.DataFrame({\"Player\": df[\"Player\"].unique()})\n",
        "        agg_num = g[num_cols].agg(wavg) if num_cols else pd.DataFrame({\"Player\": df[\"Player\"].unique()})\n",
        "\n",
        "        out = agg_other.merge(agg_num, on=\"Player\", how=\"left\")\n",
        "        out = out.drop(columns=[\"_w_\"], errors=\"ignore\")\n",
        "        out = make_unique_columns(out)\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] collapse_traded_players failed: {e}. Returning uncollapsed.\")\n",
        "        return df\n",
        "\n",
        "# =========================\n",
        "# Specialized parsers (use your existing ones)\n",
        "# =========================\n",
        "def parse_shot_fg_safe(path):\n",
        "    raw = safe_read_csv(path)\n",
        "    if raw is None or raw.empty:\n",
        "        return None\n",
        "    try:\n",
        "        header = raw.iloc[0].tolist()\n",
        "        data = raw.iloc[1:].copy()\n",
        "        data.columns = header\n",
        "        data = normalize_cols(data)\n",
        "        data = make_unique_columns(data)\n",
        "\n",
        "        if \"PLAYER\" in data.columns:\n",
        "            data = data.rename(columns={\"PLAYER\": \"Player\"})\n",
        "        if \"TEAM\" in data.columns:\n",
        "            data = data.rename(columns={\"TEAM\": \"Team\"})\n",
        "        if \"AGE\" in data.columns:\n",
        "            data = data.rename(columns={\"AGE\": \"Age\"})\n",
        "\n",
        "        data = data.rename(columns={\n",
        "            \"FREQ\": \"FG_FREQ\",\n",
        "            \"2FG FREQ\": \"FG2_FREQ\",\n",
        "            \"3FG FREQ\": \"FG3_FREQ\",\n",
        "            \"2FGA\": \"FG2A\",\n",
        "            \"3PA\": \"FG3A\",\n",
        "        })\n",
        "\n",
        "        data = ensure_player_col(data, os.path.basename(path))\n",
        "        if data is None:\n",
        "            return None\n",
        "        data = ensure_team_col(data)\n",
        "        data = make_unique_columns(data)\n",
        "\n",
        "        for c in data.columns:\n",
        "            if c in [\"Player\",\"Team\"]:\n",
        "                continue\n",
        "            data[c] = pd.to_numeric(data[c], errors=\"coerce\")\n",
        "\n",
        "        keep = [c for c in [\"Player\",\"Team\",\"Age\",\"GP\",\"FG_FREQ\",\"FG2_FREQ\",\"FG3_FREQ\",\"FGA\",\"FG2A\",\"FG3A\"] if c in data.columns]\n",
        "        return make_unique_columns(data[keep].copy())\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] parse_shot_fg_safe failed for {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_shot_dist_safe(path):\n",
        "    raw = safe_read_csv(path)\n",
        "    if raw is None or raw.empty:\n",
        "        return None\n",
        "    try:\n",
        "        df = raw.iloc[1:].copy()\n",
        "        cols = raw.columns.tolist()\n",
        "        if len(cols) < 21:\n",
        "            log(f\"[warn] Shot distance file has {len(cols)} columns (expected ~21). Skipping.\")\n",
        "            return None\n",
        "\n",
        "        df = df.rename(columns={cols[0]: \"Player\", cols[1]: \"Team\", cols[2]: \"Age\"})\n",
        "        df = ensure_player_col(df, os.path.basename(path))\n",
        "        if df is None:\n",
        "            return None\n",
        "        df = ensure_team_col(df)\n",
        "        df = make_unique_columns(df)\n",
        "\n",
        "        bucket_positions = [\n",
        "            (\"LT5\", 4),\n",
        "            (\"5_9\", 7),\n",
        "            (\"10_14\", 10),\n",
        "            (\"15_19\", 13),\n",
        "            (\"20_24\", 16),\n",
        "            (\"25_29\", 19),\n",
        "        ]\n",
        "        for name, pos in bucket_positions:\n",
        "            df[f\"{name}_FGA\"] = pd.to_numeric(df.iloc[:, pos], errors=\"coerce\")\n",
        "\n",
        "        keep = [\"Player\"] + [c for c in df.columns if c.endswith(\"_FGA\")]\n",
        "        return make_unique_columns(df[keep].copy())\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] parse_shot_dist_safe failed for {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# Injury score\n",
        "# =========================\n",
        "def load_injury_scores_safe(path):\n",
        "    inj = safe_read_csv(path)\n",
        "    if inj is None or inj.empty:\n",
        "        log(\"[warn] Injury file missing/empty. Injury scores will be all 0.\")\n",
        "        return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "\n",
        "    try:\n",
        "        inj = normalize_cols(inj)\n",
        "        inj = make_unique_columns(inj)\n",
        "\n",
        "        col_map = {c.lower(): c for c in inj.columns}\n",
        "\n",
        "        def pick_col(names):\n",
        "            for n in names:\n",
        "                if n.lower() in col_map:\n",
        "                    return col_map[n.lower()]\n",
        "            return None\n",
        "\n",
        "        player_col = pick_col([\"PLAYER\", \"Player\", \"Player Name\", \"PLAYER NAME\", \"Name\"])\n",
        "        status_col = pick_col([\"STATUS\", \"Status\"])\n",
        "        reason_col = pick_col([\"REASON\", \"Reason\"])\n",
        "        date_col = pick_col([\"DATE\", \"Date\"])\n",
        "\n",
        "        if player_col is None:\n",
        "            tmp = ensure_player_col(inj, os.path.basename(path))\n",
        "            if tmp is None:\n",
        "                return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "            inj = tmp.rename(columns={\"Player\": \"PLAYER\"})\n",
        "            player_col = \"PLAYER\"\n",
        "\n",
        "        if date_col is None:\n",
        "            inj[\"DATE\"] = pd.NaT\n",
        "            date_col = \"DATE\"\n",
        "\n",
        "        inj[\"PLAYER_STD\"] = inj[player_col].astype(str).apply(last_first_to_first_last)\n",
        "        inj[\"PLAYER_STD\"] = clean_player_name(inj[\"PLAYER_STD\"])\n",
        "        inj[\"PLAYER_KEY\"] = canonical_name_series(inj[\"PLAYER_STD\"])\n",
        "\n",
        "        inj[\"STATUS_STD\"] = inj[status_col].astype(str).str.lower().str.strip() if status_col else \"\"\n",
        "        inj[\"REASON_STD\"] = inj[reason_col].astype(str).str.lower().str.strip() if reason_col else \"\"\n",
        "        inj[\"DATE_STD\"] = pd.to_datetime(inj[date_col], errors=\"coerce\")\n",
        "\n",
        "        injury_reason_mask = (\n",
        "            inj[\"REASON_STD\"].str.contains(\"injury/illness\", na=False) |\n",
        "            inj[\"REASON_STD\"].str.contains(\"concussion\", na=False) |\n",
        "            inj[\"REASON_STD\"].str.contains(\"surgery\", na=False) |\n",
        "            inj[\"REASON_STD\"].str.contains(\"return to competition\", na=False)\n",
        "        )\n",
        "        status_mask = inj[\"STATUS_STD\"].isin([\"out\", \"out for season\", \"doubtful\", \"questionable\"])\n",
        "\n",
        "        inj2 = inj[injury_reason_mask & status_mask].copy()\n",
        "        if inj2.empty:\n",
        "            log(\"[warn] Injury filters removed all rows. Injury scores will be 0.\")\n",
        "            return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "\n",
        "        scores = inj2.groupby(\"PLAYER_KEY\", as_index=False).agg(\n",
        "            INJURY_REPORT_ENTRIES=(\"DATE_STD\", \"size\"),\n",
        "            UNIQUE_INJURY_DAYS=(\"DATE_STD\", lambda s: s.dt.date.nunique() if s.notna().any() else 0),\n",
        "        )\n",
        "        scores[\"INJURY_SCORE\"] = scores[\"UNIQUE_INJURY_DAYS\"] + 0.25 * scores[\"INJURY_REPORT_ENTRIES\"]\n",
        "        return scores\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] Injury scoring failed: {e}. Returning empty scores.\")\n",
        "        return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Main\n",
        "# =========================\n",
        "def main():\n",
        "    log(\"Working dir: \" + os.getcwd())\n",
        "    files = safe_listdir(\".\")\n",
        "    log(\"Files (first 40): \" + \", \".join(files[:40]) + (\" ...\" if len(files) > 40 else \"\"))\n",
        "\n",
        "    # ---- Choose ONLY the bottom 5 (24-25) ----\n",
        "    # Patterns are intentionally broad, but we:\n",
        "    #   - exclude 2016 automatically\n",
        "    #   - prefer tokens like \"24-25\" / \"24_25\"\n",
        "    prefer_2425 = [\"24-25\", \"24_25\", \"2024\", \"2025\"]\n",
        "\n",
        "    injury_path = find_best(\n",
        "        [\"**/*injury*.csv\"],\n",
        "        prefer_tokens=prefer_2425,\n",
        "        require_tokens=[\"injury\"]\n",
        "    )\n",
        "\n",
        "    box_path = find_best(\n",
        "        [\"**/*box*out*.csv\", \"**/*Box_Out*.csv\", \"**/*Box Out*.csv\"],\n",
        "        prefer_tokens=prefer_2425\n",
        "    )\n",
        "\n",
        "    hustle_path = find_best(\n",
        "        [\"**/*hustle*.csv\", \"**/*Hustle*.csv\"],\n",
        "        prefer_tokens=prefer_2425\n",
        "    )\n",
        "\n",
        "    general_path = find_best(\n",
        "        [\"**/General*.csv\", \"**/*general*.csv\"],\n",
        "        prefer_tokens=prefer_2425,\n",
        "        require_tokens=[\"general\"]\n",
        "    )\n",
        "\n",
        "    # Shot selection (prefer 24-25, avoid 2016)\n",
        "    shot_fg_path = find_best(\n",
        "        [\"**/*Shot*Selection*.csv\", \"**/*Field*Goals*.csv\", \"**/*Attempts*.csv\"],\n",
        "        prefer_tokens=prefer_2425\n",
        "    )\n",
        "\n",
        "    log(\"\\nUsing files (FOR TRAINING):\")\n",
        "    log(f\" injury     = {injury_path}\")\n",
        "    log(f\" box_out    = {box_path}\")\n",
        "    log(f\" hustle     = {hustle_path}\")\n",
        "    log(f\" general    = {general_path}\")\n",
        "    log(f\" shot_sel   = {shot_fg_path}\")\n",
        "\n",
        "    # Load tables\n",
        "    def load_basic(path):\n",
        "        if not path:\n",
        "            return None\n",
        "        df = safe_read_csv(path)\n",
        "        df = ensure_player_col(df, os.path.basename(path))\n",
        "        if df is None:\n",
        "            return None\n",
        "        df = ensure_team_col(df)\n",
        "        df = make_unique_columns(df)\n",
        "        return collapse_traded_players(df, weight_col=\"GP\" if \"GP\" in df.columns else \"G\")\n",
        "\n",
        "    box = load_basic(box_path)\n",
        "    hustle = load_basic(hustle_path)\n",
        "    gen = load_basic(general_path)\n",
        "\n",
        "    # Shot selection can be in either \"header row first row\" format or normal\n",
        "    shot_fg = parse_shot_fg_safe(shot_fg_path) if shot_fg_path else None\n",
        "    if shot_fg is None and shot_fg_path:\n",
        "        # fallback: treat as a normal csv\n",
        "        shot_fg = load_basic(shot_fg_path)\n",
        "\n",
        "    if shot_fg is not None:\n",
        "        shot_fg = collapse_traded_players(shot_fg, weight_col=\"GP\" if \"GP\" in shot_fg.columns else \"G\")\n",
        "\n",
        "    # Merge available tables\n",
        "    stat_tables = [t for t in [box, hustle, gen, shot_fg] if t is not None]\n",
        "    if not stat_tables:\n",
        "        log(\"[warn] No stat tables loaded. Nothing to do.\")\n",
        "        return\n",
        "\n",
        "    df = make_unique_columns(stat_tables[0])\n",
        "    for nxt in stat_tables[1:]:\n",
        "        nxt = make_unique_columns(nxt)\n",
        "        df = df.merge(nxt, on=\"Player\", how=\"outer\", suffixes=(\"\", \"_DUP\"))\n",
        "        df = make_unique_columns(df)\n",
        "\n",
        "    # Player key\n",
        "    df[\"PLAYER_KEY\"] = canonical_name_series(df[\"Player\"])\n",
        "\n",
        "    # Injury scores\n",
        "    inj_scores = load_injury_scores_safe(injury_path) if injury_path else pd.DataFrame(\n",
        "        columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"]\n",
        "    )\n",
        "\n",
        "    df = df.merge(inj_scores, on=\"PLAYER_KEY\", how=\"left\")\n",
        "    for c in [\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"]:\n",
        "        if c not in df.columns:\n",
        "            df[c] = 0\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # Target\n",
        "    y = np.log1p(df[\"INJURY_SCORE\"].values.astype(float))\n",
        "\n",
        "    # Features\n",
        "    exclude = {\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"}\n",
        "    feature_cols = []\n",
        "    X = df.copy()\n",
        "\n",
        "    for c in list(X.columns):\n",
        "        if c in [\"Player\",\"PLAYER_KEY\"] or c in exclude:\n",
        "            continue\n",
        "\n",
        "        col = X[c]\n",
        "        if isinstance(col, pd.DataFrame):\n",
        "            col = col.iloc[:, 0]\n",
        "            X[c] = col\n",
        "\n",
        "        if not pd.api.types.is_numeric_dtype(col):\n",
        "            coerced = pd.to_numeric(col, errors=\"coerce\")\n",
        "            if coerced.notna().sum() > 0:\n",
        "                X[c] = coerced\n",
        "                col = X[c]\n",
        "\n",
        "        if pd.api.types.is_numeric_dtype(col):\n",
        "            feature_cols.append(c)\n",
        "\n",
        "    if not feature_cols:\n",
        "        log(\"[warn] No numeric features found. Saving merged dataset for inspection.\")\n",
        "        df.to_csv(\"player_season_24_25_with_injury_score.csv\", index=False)\n",
        "        log(\"Saved: player_season_24_25_with_injury_score.csv\")\n",
        "        return\n",
        "\n",
        "    X = X[feature_cols]\n",
        "\n",
        "    # Model\n",
        "    model = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"reg\", HistGradientBoostingRegressor(\n",
        "            max_depth=3, learning_rate=0.06, max_iter=400, random_state=42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # CV predictions\n",
        "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    preds = np.zeros(len(df))\n",
        "    for tr, te in cv.split(X):\n",
        "        model.fit(X.iloc[tr], y[tr])\n",
        "        preds[te] = model.predict(X.iloc[te])\n",
        "\n",
        "    pred_score = np.expm1(preds)\n",
        "    true_score = df[\"INJURY_SCORE\"].values.astype(float)\n",
        "\n",
        "    log(\"\\nRanking evaluation (predicting injury burden):\")\n",
        "    if HAVE_SCIPY:\n",
        "        rho, pval = spearmanr(pred_score, true_score)\n",
        "        log(f\" Spearman rho(pred, true injury_score): {rho:.4f} (p={pval:.2e})\")\n",
        "\n",
        "    k = max(1, int(0.10 * len(true_score)))\n",
        "    top_idx = np.argsort(-pred_score)[:k]\n",
        "    lift = true_score[top_idx].mean() / (true_score.mean() + 1e-9)\n",
        "    log(f\" Top 10% avg injury_score: {true_score[top_idx].mean():.3f}\")\n",
        "    log(f\" Overall avg injury_score: {true_score.mean():.3f}\")\n",
        "    log(f\" Top-10% lift: {lift:.3f}x\")\n",
        "\n",
        "    for thr in [1, 3, 5, 8]:\n",
        "        y_bin = (true_score >= thr).astype(int)\n",
        "        if y_bin.sum() < 10 or y_bin.sum() > len(y_bin) - 10:\n",
        "            continue\n",
        "        auc = roc_auc_score(y_bin, pred_score)\n",
        "        log(f\" AUC for injury_score >= {thr}: {auc:.4f} (positives={int(y_bin.sum())})\")\n",
        "\n",
        "    # Save outputs\n",
        "    out = df.copy()\n",
        "    out[\"PRED_INJURY_SCORE\"] = pred_score\n",
        "    out[\"PRED_INJURY_RANK\"] = out[\"PRED_INJURY_SCORE\"].rank(ascending=False, method=\"min\").astype(int)\n",
        "\n",
        "    out.to_csv(\"player_season_24_25_with_injury_score.csv\", index=False)\n",
        "    out[[\"Player\",\"PRED_INJURY_SCORE\",\"PRED_INJURY_RANK\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"]] \\\n",
        "        .sort_values(\"PRED_INJURY_RANK\") \\\n",
        "        .to_csv(\"player_injury_risk_scores_24_25.csv\", index=False)\n",
        "\n",
        "    log(\"\\nSaved:\")\n",
        "    log(\" player_season_24_25_with_injury_score.csv\")\n",
        "    log(\" player_injury_risk_scores_24_25.csv\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-lMO_n0t6sNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20706892-ef76-4063-e464-fb6dd2cc7b2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "df = pd.read_csv(\"player_season_24_25_with_injury_score.csv\")\n",
        "\n",
        "y = df[\"INJURY_SCORE\"].values.astype(float)\n",
        "\n",
        "groups = {\n",
        "    \"Exposure\": [c for c in df.columns if c.lower() in [\"age\", \"gp\", \"min\", \"minutes\"]],\n",
        "\n",
        "    \"Shooting Profile\": [c for c in df.columns if (\n",
        "        \"FG\" in c or \"FGA\" in c or \"_FREQ\" in c or \"_FGA\" in c\n",
        "    )],\n",
        "\n",
        "    \"Hustle\": [c for c in df.columns if any(\n",
        "        k in c.lower() for k in [\"hustle\", \"deflect\", \"loose\", \"charge\", \"contest\"]\n",
        "    )],\n",
        "\n",
        "    \"Box Outs\": [c for c in df.columns if \"box\" in c.lower()],\n",
        "\n",
        "    \"Drives\": [c for c in df.columns if \"drive\" in c.lower()],\n",
        "}\n",
        "\n",
        "rows = []\n",
        "\n",
        "for gname, cols in groups.items():\n",
        "    cols = [c for c in cols if c in df.columns]\n",
        "    if not cols:\n",
        "        continue\n",
        "\n",
        "    Xg = df[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "\n",
        "    # ðŸ”‘ key change: aggregate FIRST, then rank\n",
        "    group_sum = Xg.sum(axis=1)\n",
        "\n",
        "    # if still constant, skip\n",
        "    if group_sum.nunique() <= 1:\n",
        "        continue\n",
        "\n",
        "    group_signal = group_sum.rank(pct=True)\n",
        "\n",
        "    rho, _ = spearmanr(group_signal, y)\n",
        "\n",
        "    rows.append({\n",
        "        \"group\": gname,\n",
        "        \"spearman_rho_with_injury\": rho,\n",
        "        \"abs_rho\": abs(rho),\n",
        "        \"n_features_used\": len(cols)\n",
        "    })\n",
        "\n",
        "result = (\n",
        "    pd.DataFrame(rows)\n",
        "    .sort_values(\"abs_rho\", ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"\\nGroups most associated with injury burden (Spearman rho):\\n\")\n",
        "display(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "c2WuYlcwKYCz",
        "outputId": "c3f358e2-c82f-4e38-f761-cb29e8690c78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Groups most associated with injury burden (Spearman rho):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              group  spearman_rho_with_injury   abs_rho  n_features_used\n",
              "0          Exposure                  0.543839  0.543839                4\n",
              "1            Hustle                  0.514442  0.514442               10\n",
              "2          Box Outs                  0.504578  0.504578                9\n",
              "3  Shooting Profile                  0.484031  0.484031                4\n",
              "4            Drives                  0.464235  0.464235                1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a650511-30b4-4396-be30-1dd2fa3003da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>spearman_rho_with_injury</th>\n",
              "      <th>abs_rho</th>\n",
              "      <th>n_features_used</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Exposure</td>\n",
              "      <td>0.543839</td>\n",
              "      <td>0.543839</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hustle</td>\n",
              "      <td>0.514442</td>\n",
              "      <td>0.514442</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Box Outs</td>\n",
              "      <td>0.504578</td>\n",
              "      <td>0.504578</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shooting Profile</td>\n",
              "      <td>0.484031</td>\n",
              "      <td>0.484031</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drives</td>\n",
              "      <td>0.464235</td>\n",
              "      <td>0.464235</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a650511-30b4-4396-be30-1dd2fa3003da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a650511-30b4-4396-be30-1dd2fa3003da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a650511-30b4-4396-be30-1dd2fa3003da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4816c4e6-bccd-42d2-a039-ca91bf74da0d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4816c4e6-bccd-42d2-a039-ca91bf74da0d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Hustle\",\n          \"Drives\",\n          \"Box Outs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spearman_rho_with_injury\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030252453926437214,\n        \"min\": 0.4642346926309149,\n        \"max\": 0.5438394501824788,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5144415149460528,\n          0.4642346926309149,\n          0.5045782530696175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abs_rho\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030252453926437214,\n        \"min\": 0.4642346926309149,\n        \"max\": 0.5438394501824788,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5144415149460528,\n          0.4642346926309149,\n          0.5045782530696175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_features_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# 1. Load data\n",
        "df = pd.read_csv(\"player_season_24_25_with_injury_score.csv\")\n",
        "\n",
        "# 2. Ensure the target exists and is numeric\n",
        "if \"INJURY_SCORE\" not in df.columns:\n",
        "    print(\"Error: 'INJURY_SCORE' not found in CSV. Check your first script's output.\")\n",
        "else:\n",
        "    y = pd.to_numeric(df[\"INJURY_SCORE\"], errors=\"coerce\").fillna(0).values\n",
        "\n",
        "    exclude = {\n",
        "        \"Player\", \"PLAYER_KEY\", \"INJURY_SCORE\", \"UNIQUE_INJURY_DAYS\",\n",
        "        \"INJURY_REPORT_ENTRIES\", \"PRED_INJURY_SCORE\", \"PRED_INJURY_RANK\"\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in exclude:\n",
        "            continue\n",
        "\n",
        "        # Force numeric conversion\n",
        "        s = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "        # Skip if all NaN or if it's a constant value (0 variance)\n",
        "        if s.isna().all() or s.nunique(dropna=True) <= 1:\n",
        "            continue\n",
        "\n",
        "        # Fill NaNs for the correlation calculation\n",
        "        s_filled = s.fillna(0)\n",
        "\n",
        "        # Calculate Spearman Rho\n",
        "        rho, pval = spearmanr(s_filled, y)\n",
        "\n",
        "        if not np.isnan(rho):\n",
        "            rows.append({\n",
        "                \"stat\": col,\n",
        "                \"spearman_rho_with_injury\": rho,\n",
        "                \"abs_rho\": abs(rho),\n",
        "                \"p_value\": pval\n",
        "            })\n",
        "\n",
        "    # 3. Check if we actually found anything before sorting\n",
        "    if len(rows) > 0:\n",
        "        result = pd.DataFrame(rows)\n",
        "        result = result.sort_values(\"abs_rho\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "        print(\"\\nIndividual stats most associated with injury burden (Spearman rho):\\n\")\n",
        "        # Using print(result.head()) for standard scripts, display() for notebooks\n",
        "        print(result.head(30))\n",
        "    else:\n",
        "        print(\"No valid numeric columns found to correlate! Check if your CSV contains numeric data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JMLXvA7Lol3",
        "outputId": "beac9a8c-2af7-4c5b-90d1-70f16278b4eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Individual stats most associated with injury burden (Spearman rho):\n",
            "\n",
            "                           stat  spearman_rho_with_injury   abs_rho  \\\n",
            "0                           Min                  0.653165  0.653165   \n",
            "1                            GP                  0.561377  0.561377   \n",
            "2                  DEF Box Outs                  0.537712  0.537712   \n",
            "3          Team Reb On Box Outs                  0.533847  0.533847   \n",
            "4                      Box Outs                  0.533595  0.533595   \n",
            "5                       Min_DUP                  0.531561  0.531561   \n",
            "6           Contested 3PT Shots                  0.492954  0.492954   \n",
            "7   PCT Player Reb When Box Out                  0.490849  0.490849   \n",
            "8                        GP_DUP                  0.485480  0.485480   \n",
            "9     PCT Team Reb When Box Out                  0.485321  0.485321   \n",
            "10                      FGA_DUP                  0.480278  0.480278   \n",
            "11             PCT Box Outs Def                  0.478217  0.478217   \n",
            "12               Contested Shot                  0.477764  0.477764   \n",
            "13       Player Reb On Box Outs                  0.474802  0.474802   \n",
            "14                          PTS                  0.470922  0.470922   \n",
            "15                          MIN                  0.467723  0.467723   \n",
            "16                          FGA                  0.464760  0.464760   \n",
            "17                          FTM                  0.464275  0.464275   \n",
            "18                       DRIVES                  0.464235  0.464235   \n",
            "19                          FGM                  0.463729  0.463729   \n",
            "20                          FTA                  0.462304  0.462304   \n",
            "21                           PF                  0.461276  0.461276   \n",
            "22                  Deflections                  0.460816  0.460816   \n",
            "23        Loose Balls Recovered                  0.459814  0.459814   \n",
            "24                          Age                  0.459739  0.459739   \n",
            "25    DEF Loose Balls Recovered                  0.452219  0.452219   \n",
            "26                           TO                  0.447969  0.447969   \n",
            "27                   Age_DUP__2                  0.442447  0.442447   \n",
            "28    OFF Loose Balls Recovered                  0.441745  0.441745   \n",
            "29                         PASS                  0.441459  0.441459   \n",
            "\n",
            "         p_value  \n",
            "0   4.078652e-94  \n",
            "1   1.184483e-64  \n",
            "2   1.819195e-58  \n",
            "3   1.675665e-57  \n",
            "4   1.935646e-57  \n",
            "5   6.150824e-57  \n",
            "6   5.023970e-48  \n",
            "7   1.428236e-47  \n",
            "8   1.987899e-46  \n",
            "9   2.147545e-46  \n",
            "10  2.437854e-45  \n",
            "11  6.504598e-45  \n",
            "12  8.061378e-45  \n",
            "13  3.258548e-44  \n",
            "14  1.988644e-43  \n",
            "15  8.683143e-43  \n",
            "16  3.353541e-42  \n",
            "17  4.178937e-42  \n",
            "18  4.256271e-42  \n",
            "19  5.350769e-42  \n",
            "20  1.017998e-41  \n",
            "21  1.615697e-41  \n",
            "22  1.985607e-41  \n",
            "23  3.108120e-41  \n",
            "24  3.214155e-41  \n",
            "25  8.846217e-40  \n",
            "26  5.555057e-39  \n",
            "27  5.818207e-38  \n",
            "28  7.816550e-38  \n",
            "29  8.817659e-38  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Processing Logic (Same as your training script)\n",
        "def prepare_new_data(file_paths):\n",
        "    # Load and clean each file\n",
        "    # (Simplified versions of your robust functions)\n",
        "    dfs = []\n",
        "    for path in file_paths:\n",
        "        df = pd.read_csv(path)\n",
        "        # Normalize columns (remove newlines, handle headers)\n",
        "        if \"Unnamed\" in df.columns[0]: # Specific to the Shot Selection file format\n",
        "            df.columns = df.iloc[0]\n",
        "            df = df.drop(0)\n",
        "\n",
        "        # Standardize Player column\n",
        "        for col in df.columns:\n",
        "            if col.lower() in [\"player\", \"player_name\"]:\n",
        "                df = df.rename(columns={col: \"Player\"})\n",
        "        dfs.append(df)\n",
        "\n",
        "    # Merge all stats on Player name\n",
        "    merged = dfs[0]\n",
        "    for nxt in dfs[1:]:\n",
        "        merged = merged.merge(nxt, on=\"Player\", how=\"inner\", suffixes=(\"\", \"_dup\"))\n",
        "\n",
        "    # Remove duplicate columns and keep only numeric features\n",
        "    merged = merged.loc[:,~merged.columns.str.contains('_dup')]\n",
        "    return merged\n",
        "\n",
        "# 2. RUNNING THE PREDICTION\n",
        "# List your 2016-17 files\n",
        "current_files = [\n",
        "    \"2016-17_Box Out.csv\",\n",
        "    \"2016-17_Hustle_Stats.csv\",\n",
        "    \"2016-17_Shot_Selection.csv\",\n",
        "    \"2016-17_Tracking_Drives.csv\"\n",
        "]\n",
        "\n",
        "# Process the data\n",
        "new_season_data = prepare_new_data(current_files)\n",
        "\n",
        "# Align features with what your model expects\n",
        "# (Note: X_new must have the exact same columns as the X you used to train)\n",
        "X_new = new_season_data[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "# Generate the Risk Scores\n",
        "# We use expm1 because we trained on log-scaled injury scores\n",
        "log_predictions = model.predict(X_new)\n",
        "new_season_data[\"PREDICTED_INJURY_SCORE\"] = np.expm1(log_predictions)\n",
        "\n",
        "# Create the Leaderboard\n",
        "leaderboard = new_season_data[[\"Player\", \"PREDICTED_INJURY_SCORE\"]].sort_values(\n",
        "    \"PREDICTED_INJURY_SCORE\", ascending=False\n",
        ")\n",
        "\n",
        "print(\"Top 10 Players at Risk (2016-17 Stats):\")\n",
        "print(leaderboard.head(10))"
      ],
      "metadata": {
        "id": "GgccozBWsiri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "072b29ee-1b05-4370-e907-fc4ee433b713"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '2016-17_Box Out.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3015599267.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Process the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mnew_season_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_new_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Align features with what your model expects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3015599267.py\u001b[0m in \u001b[0;36mprepare_new_data\u001b[0;34m(file_paths)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Normalize columns (remove newlines, handle headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"Unnamed\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Specific to the Shot Selection file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2016-17_Box Out.csv'"
          ]
        }
      ]
    }
  ]
}