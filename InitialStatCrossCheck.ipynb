{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVIMZNYG9L6Anj+wZ7P54g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanCP26/nbaPredictor/blob/main/InitialStatCrossCheck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_PBfKP9jgtN",
        "outputId": "53d30913-8b08-4b0d-9450-9ec5b55c0ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working dir: /content\n",
            "Files (first 40): .config, .ipynb_checkpoints, drive, injury_stats_24_25.csv, player_injury_risk_scores_24_25.csv, player_season_24_25_with_injury_score.csv, sample_data, test, train\n",
            "\n",
            "Using files (FOR TRAINING):\n",
            " injury     = injury_stats_24_25.csv\n",
            " box_out    = train/Box Out Statistics - Sheet1.csv\n",
            " hustle     = train/Hustle Statistics - Sheet1.csv\n",
            " general    = train/General + drives - Sheet1 (1).csv\n",
            " shot_sel   = train/Shot Selection Stats - Sheet2.csv\n",
            "\n",
            "Ranking evaluation (predicting injury burden):\n",
            " Spearman rho(pred, true injury_score): 0.7294 (p=9.04e-128)\n",
            " Top 10% avg injury_score: 37.122\n",
            " Overall avg injury_score: 12.413\n",
            " Top-10% lift: 2.990x\n",
            " AUC for injury_score >= 1: 0.8912 (positives=444)\n",
            " AUC for injury_score >= 3: 0.8871 (positives=384)\n",
            " AUC for injury_score >= 5: 0.8848 (positives=358)\n",
            " AUC for injury_score >= 8: 0.8892 (positives=299)\n",
            "\n",
            "Saved:\n",
            " player_season_24_25_with_injury_score.csv\n",
            " player_injury_risk_scores_24_25.csv\n",
            "Saved model to: injury_model.pkl\n",
            "Saved features to: feature_cols.pkl\n"
          ]
        }
      ],
      "source": [
        "import os, glob, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "try:\n",
        "    from scipy.stats import spearmanr\n",
        "    HAVE_SCIPY = True\n",
        "except Exception:\n",
        "    HAVE_SCIPY = False\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Logging\n",
        "# =========================\n",
        "def log(msg):\n",
        "    print(msg)\n",
        "\n",
        "def safe_listdir(path=\".\"):\n",
        "    try:\n",
        "        return sorted(os.listdir(path))\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "# =========================\n",
        "# File discovery (FIXED)\n",
        "#   - Prefer 24-25\n",
        "#   - Exclude 2016-17 and 2016_17\n",
        "# =========================\n",
        "def is_bad_file(path: str) -> bool:\n",
        "    p = os.path.basename(path).lower()\n",
        "    return (\"2016-17\" in p) or (\"2016_17\" in p) or (\"2016\" in p)\n",
        "\n",
        "def find_best(patterns, prefer_tokens=None, require_tokens=None):\n",
        "    \"\"\"\n",
        "    Find best matching file across patterns.\n",
        "    - Filters out 2016 files\n",
        "    - If prefer_tokens given, scores higher for those\n",
        "    - If require_tokens given, only keeps files containing all require tokens\n",
        "    \"\"\"\n",
        "    hits = []\n",
        "    for pat in patterns:\n",
        "        hits.extend(glob.glob(pat, recursive=True))\n",
        "\n",
        "    hits = [h for h in hits if os.path.isfile(h)]\n",
        "    hits = [h for h in hits if not is_bad_file(h)]\n",
        "\n",
        "    if require_tokens:\n",
        "        req = [t.lower() for t in require_tokens]\n",
        "        hits = [h for h in hits if all(t in os.path.basename(h).lower() for t in req)]\n",
        "\n",
        "    if not hits:\n",
        "        return None\n",
        "\n",
        "    def score(h):\n",
        "        name = os.path.basename(h).lower()\n",
        "        s = 0\n",
        "        if prefer_tokens:\n",
        "            for t in prefer_tokens:\n",
        "                if t.lower() in name:\n",
        "                    s += 10\n",
        "        # shorter path/name tie-breaker\n",
        "        s -= 0.001 * len(h)\n",
        "        return s\n",
        "\n",
        "    hits = sorted(hits, key=lambda h: (-score(h), len(h), h))\n",
        "    return hits[0]\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Robust column utilities\n",
        "# =========================\n",
        "def normalize_cols(df):\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns.astype(str)\n",
        "        .str.replace(\"\\n\", \" \", regex=False)\n",
        "        .str.replace(\"%\", \"PCT\", regex=False)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def make_unique_columns(df):\n",
        "    cols = list(df.columns)\n",
        "    seen = {}\n",
        "    new_cols = []\n",
        "    for c in cols:\n",
        "        if c not in seen:\n",
        "            seen[c] = 1\n",
        "            new_cols.append(c)\n",
        "        else:\n",
        "            seen[c] += 1\n",
        "            new_cols.append(f\"{c}__{seen[c]}\")\n",
        "    df = df.copy()\n",
        "    df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "# =========================\n",
        "# Player name helpers\n",
        "# =========================\n",
        "def clean_player_name(s):\n",
        "    return (\n",
        "        s.astype(str)\n",
        "        .str.replace(\"\\u00a0\", \" \", regex=False)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "\n",
        "def last_first_to_first_last(name):\n",
        "    if not isinstance(name, str):\n",
        "        name = str(name)\n",
        "    if \",\" in name:\n",
        "        last, first = [x.strip() for x in name.split(\",\", 1)]\n",
        "        return f\"{first} {last}\".strip()\n",
        "    return name.strip()\n",
        "\n",
        "def canonical_name_series(s):\n",
        "    s = clean_player_name(s).str.lower()\n",
        "    s = s.str.replace(r\"[.\\']\", \"\", regex=True)\n",
        "    s = s.str.replace(\",\", \"\", regex=False)\n",
        "    s = s.str.replace(r\"\\b(jr|sr|ii|iii|iv)\\b\", \"\", regex=True)\n",
        "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "    return s\n",
        "\n",
        "# =========================\n",
        "# Safe read\n",
        "# =========================\n",
        "def safe_read_csv(path):\n",
        "    if path is None:\n",
        "        return None\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        df = normalize_cols(df)\n",
        "        df = make_unique_columns(df)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] Could not read CSV '{path}': {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# Player/team column detection\n",
        "# =========================\n",
        "def ensure_player_col(df, filename=\"(unknown)\"):\n",
        "    if df is None or not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        log(f\"[warn] Empty/missing dataframe for {filename}. Skipping.\")\n",
        "        return None\n",
        "\n",
        "    df = normalize_cols(df)\n",
        "    df = make_unique_columns(df)\n",
        "\n",
        "    for c in list(df.columns):\n",
        "        if c.strip().lower() in [\"player\", \"player_name\", \"player name\", \"name\", \"playerfullname\", \"player_full_name\", \"player full name\"]:\n",
        "            df = df.rename(columns={c: \"Player\"})\n",
        "            break\n",
        "\n",
        "    if \"PLAYER\" in df.columns and \"Player\" not in df.columns:\n",
        "        df = df.rename(columns={\"PLAYER\": \"Player\"})\n",
        "\n",
        "    if \"Player\" not in df.columns:\n",
        "        obj_cols = [c for c in df.columns if pd.api.types.is_object_dtype(df[c])]\n",
        "        if obj_cols:\n",
        "            df = df.rename(columns={obj_cols[0]: \"Player\"})\n",
        "            log(f\"[warn] No explicit player column in {filename}. Using '{obj_cols[0]}' as Player.\")\n",
        "        else:\n",
        "            log(f\"[warn] Could not find player column in {filename}. Columns={df.columns.tolist()[:30]}\")\n",
        "            return None\n",
        "\n",
        "    df[\"Player\"] = clean_player_name(df[\"Player\"])\n",
        "    return df\n",
        "\n",
        "def ensure_team_col(df):\n",
        "    if df is None:\n",
        "        return None\n",
        "    df = df.copy()\n",
        "    if \"TEAM\" in df.columns and \"Team\" not in df.columns:\n",
        "        df = df.rename(columns={\"TEAM\": \"Team\"})\n",
        "    if \"Team\" not in df.columns:\n",
        "        for c in list(df.columns):\n",
        "            if c.strip().lower() in [\"team\", \"tm\", \"team_abbreviation\"]:\n",
        "                df = df.rename(columns={c: \"Team\"})\n",
        "                break\n",
        "    return df\n",
        "\n",
        "# =========================\n",
        "# Collapse traded players (safe)\n",
        "# =========================\n",
        "def collapse_traded_players(df, weight_col=\"GP\"):\n",
        "    if df is None or \"Player\" not in df.columns:\n",
        "        return df\n",
        "    try:\n",
        "        df = df.copy()\n",
        "        df = ensure_team_col(df)\n",
        "        df = make_unique_columns(df)\n",
        "\n",
        "        if \"Team\" in df.columns:\n",
        "            tot_mask = df[\"Team\"].astype(str).str.upper().eq(\"TOT\")\n",
        "            players_with_tot = set(df.loc[tot_mask, \"Player\"].unique())\n",
        "            if players_with_tot:\n",
        "                df = pd.concat([\n",
        "                    df[df[\"Player\"].isin(players_with_tot) & tot_mask],\n",
        "                    df[~df[\"Player\"].isin(players_with_tot)]\n",
        "                ], ignore_index=True)\n",
        "\n",
        "        if df[\"Player\"].nunique() == len(df):\n",
        "            return df\n",
        "\n",
        "        if weight_col in df.columns:\n",
        "            w = pd.to_numeric(df[weight_col], errors=\"coerce\").fillna(1.0).values\n",
        "        else:\n",
        "            w = np.ones(len(df))\n",
        "        df[\"_w_\"] = w\n",
        "\n",
        "        for c in df.columns:\n",
        "            if c in [\"Player\", \"Team\", \"_w_\"]:\n",
        "                continue\n",
        "            if pd.api.types.is_object_dtype(df[c]):\n",
        "                tmp = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "                if tmp.notna().sum() > 0:\n",
        "                    df[c] = tmp\n",
        "\n",
        "        num_cols = [c for c in df.columns if c not in [\"Player\",\"Team\",\"_w_\"] and pd.api.types.is_numeric_dtype(df[c])]\n",
        "        other_cols = [c for c in df.columns if c not in num_cols + [\"_w_\"]]\n",
        "\n",
        "        def wavg(x):\n",
        "            x = pd.to_numeric(x, errors=\"coerce\")\n",
        "            ww = df.loc[x.index, \"_w_\"].values\n",
        "            mask = ~x.isna()\n",
        "            if mask.sum() == 0:\n",
        "                return np.nan\n",
        "            return np.average(x[mask], weights=ww[mask])\n",
        "\n",
        "        g = df.groupby(\"Player\", as_index=False)\n",
        "        agg_other = g[other_cols].first() if other_cols else pd.DataFrame({\"Player\": df[\"Player\"].unique()})\n",
        "        agg_num = g[num_cols].agg(wavg) if num_cols else pd.DataFrame({\"Player\": df[\"Player\"].unique()})\n",
        "\n",
        "        out = agg_other.merge(agg_num, on=\"Player\", how=\"left\")\n",
        "        out = out.drop(columns=[\"_w_\"], errors=\"ignore\")\n",
        "        out = make_unique_columns(out)\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] collapse_traded_players failed: {e}. Returning uncollapsed.\")\n",
        "        return df\n",
        "\n",
        "# =========================\n",
        "# Specialized parsers (use your existing ones)\n",
        "# =========================\n",
        "def parse_shot_fg_safe(path):\n",
        "    raw = safe_read_csv(path)\n",
        "    if raw is None or raw.empty:\n",
        "        return None\n",
        "    try:\n",
        "        header = raw.iloc[0].tolist()\n",
        "        data = raw.iloc[1:].copy()\n",
        "        data.columns = header\n",
        "        data = normalize_cols(data)\n",
        "        data = make_unique_columns(data)\n",
        "\n",
        "        if \"PLAYER\" in data.columns:\n",
        "            data = data.rename(columns={\"PLAYER\": \"Player\"})\n",
        "        if \"TEAM\" in data.columns:\n",
        "            data = data.rename(columns={\"TEAM\": \"Team\"})\n",
        "        if \"AGE\" in data.columns:\n",
        "            data = data.rename(columns={\"AGE\": \"Age\"})\n",
        "\n",
        "        data = data.rename(columns={\n",
        "            \"FREQ\": \"FG_FREQ\",\n",
        "            \"2FG FREQ\": \"FG2_FREQ\",\n",
        "            \"3FG FREQ\": \"FG3_FREQ\",\n",
        "            \"2FGA\": \"FG2A\",\n",
        "            \"3PA\": \"FG3A\",\n",
        "        })\n",
        "\n",
        "        data = ensure_player_col(data, os.path.basename(path))\n",
        "        if data is None:\n",
        "            return None\n",
        "        data = ensure_team_col(data)\n",
        "        data = make_unique_columns(data)\n",
        "\n",
        "        for c in data.columns:\n",
        "            if c in [\"Player\",\"Team\"]:\n",
        "                continue\n",
        "            data[c] = pd.to_numeric(data[c], errors=\"coerce\")\n",
        "\n",
        "        keep = [c for c in [\"Player\",\"Team\",\"Age\",\"GP\",\"FG_FREQ\",\"FG2_FREQ\",\"FG3_FREQ\",\"FGA\",\"FG2A\",\"FG3A\"] if c in data.columns]\n",
        "        return make_unique_columns(data[keep].copy())\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] parse_shot_fg_safe failed for {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def parse_shot_dist_safe(path):\n",
        "    raw = safe_read_csv(path)\n",
        "    if raw is None or raw.empty:\n",
        "        return None\n",
        "    try:\n",
        "        df = raw.iloc[1:].copy()\n",
        "        cols = raw.columns.tolist()\n",
        "        if len(cols) < 21:\n",
        "            log(f\"[warn] Shot distance file has {len(cols)} columns (expected ~21). Skipping.\")\n",
        "            return None\n",
        "\n",
        "        df = df.rename(columns={cols[0]: \"Player\", cols[1]: \"Team\", cols[2]: \"Age\"})\n",
        "        df = ensure_player_col(df, os.path.basename(path))\n",
        "        if df is None:\n",
        "            return None\n",
        "        df = ensure_team_col(df)\n",
        "        df = make_unique_columns(df)\n",
        "\n",
        "        bucket_positions = [\n",
        "            (\"LT5\", 4),\n",
        "            (\"5_9\", 7),\n",
        "            (\"10_14\", 10),\n",
        "            (\"15_19\", 13),\n",
        "            (\"20_24\", 16),\n",
        "            (\"25_29\", 19),\n",
        "        ]\n",
        "        for name, pos in bucket_positions:\n",
        "            df[f\"{name}_FGA\"] = pd.to_numeric(df.iloc[:, pos], errors=\"coerce\")\n",
        "\n",
        "        keep = [\"Player\"] + [c for c in df.columns if c.endswith(\"_FGA\")]\n",
        "        return make_unique_columns(df[keep].copy())\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] parse_shot_dist_safe failed for {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# Injury score\n",
        "# =========================\n",
        "def load_injury_scores_safe(path):\n",
        "    inj = safe_read_csv(path)\n",
        "    if inj is None or inj.empty:\n",
        "        log(\"[warn] Injury file missing/empty. Injury scores will be all 0.\")\n",
        "        return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "\n",
        "    try:\n",
        "        inj = normalize_cols(inj)\n",
        "        inj = make_unique_columns(inj)\n",
        "\n",
        "        col_map = {c.lower(): c for c in inj.columns}\n",
        "\n",
        "        def pick_col(names):\n",
        "            for n in names:\n",
        "                if n.lower() in col_map:\n",
        "                    return col_map[n.lower()]\n",
        "            return None\n",
        "\n",
        "        player_col = pick_col([\"PLAYER\", \"Player\", \"Player Name\", \"PLAYER NAME\", \"Name\"])\n",
        "        status_col = pick_col([\"STATUS\", \"Status\"])\n",
        "        reason_col = pick_col([\"REASON\", \"Reason\"])\n",
        "        date_col = pick_col([\"DATE\", \"Date\"])\n",
        "\n",
        "        if player_col is None:\n",
        "            tmp = ensure_player_col(inj, os.path.basename(path))\n",
        "            if tmp is None:\n",
        "                return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "            inj = tmp.rename(columns={\"Player\": \"PLAYER\"})\n",
        "            player_col = \"PLAYER\"\n",
        "\n",
        "        if date_col is None:\n",
        "            inj[\"DATE\"] = pd.NaT\n",
        "            date_col = \"DATE\"\n",
        "\n",
        "        inj[\"PLAYER_STD\"] = inj[player_col].astype(str).apply(last_first_to_first_last)\n",
        "        inj[\"PLAYER_STD\"] = clean_player_name(inj[\"PLAYER_STD\"])\n",
        "        inj[\"PLAYER_KEY\"] = canonical_name_series(inj[\"PLAYER_STD\"])\n",
        "\n",
        "        inj[\"STATUS_STD\"] = inj[status_col].astype(str).str.lower().str.strip() if status_col else \"\"\n",
        "        inj[\"REASON_STD\"] = inj[reason_col].astype(str).str.lower().str.strip() if reason_col else \"\"\n",
        "        inj[\"DATE_STD\"] = pd.to_datetime(inj[date_col], errors=\"coerce\")\n",
        "\n",
        "        injury_reason_mask = (\n",
        "            inj[\"REASON_STD\"].str.contains(\"injury/illness\", na=False) |\n",
        "            inj[\"REASON_STD\"].str.contains(\"concussion\", na=False) |\n",
        "            inj[\"REASON_STD\"].str.contains(\"surgery\", na=False) |\n",
        "            inj[\"REASON_STD\"].str.contains(\"return to competition\", na=False)\n",
        "        )\n",
        "        status_mask = inj[\"STATUS_STD\"].isin([\"out\", \"out for season\", \"doubtful\", \"questionable\"])\n",
        "\n",
        "        inj2 = inj[injury_reason_mask & status_mask].copy()\n",
        "        if inj2.empty:\n",
        "            log(\"[warn] Injury filters removed all rows. Injury scores will be 0.\")\n",
        "            return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "\n",
        "        scores = inj2.groupby(\"PLAYER_KEY\", as_index=False).agg(\n",
        "            INJURY_REPORT_ENTRIES=(\"DATE_STD\", \"size\"),\n",
        "            UNIQUE_INJURY_DAYS=(\"DATE_STD\", lambda s: s.dt.date.nunique() if s.notna().any() else 0),\n",
        "        )\n",
        "        scores[\"INJURY_SCORE\"] = scores[\"UNIQUE_INJURY_DAYS\"] + 0.25 * scores[\"INJURY_REPORT_ENTRIES\"]\n",
        "        return scores\n",
        "    except Exception as e:\n",
        "        log(f\"[warn] Injury scoring failed: {e}. Returning empty scores.\")\n",
        "        return pd.DataFrame(columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"])\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Main\n",
        "# =========================\n",
        "def main():\n",
        "    log(\"Working dir: \" + os.getcwd())\n",
        "    files = safe_listdir(\".\")\n",
        "    log(\"Files (first 40): \" + \", \".join(files[:40]) + (\" ...\" if len(files) > 40 else \"\"))\n",
        "\n",
        "    # ---- Choose ONLY the bottom 5 (24-25) ----\n",
        "    # Patterns are intentionally broad, but we:\n",
        "    #   - exclude 2016 automatically\n",
        "    #   - prefer tokens like \"24-25\" / \"24_25\"\n",
        "    prefer_2425 = [\"24-25\", \"24_25\", \"2024\", \"2025\"]\n",
        "\n",
        "    injury_path = find_best(\n",
        "        [\"**/*injury*.csv\"],\n",
        "        prefer_tokens=prefer_2425,\n",
        "        require_tokens=[\"injury\"]\n",
        "    )\n",
        "\n",
        "    box_path = find_best(\n",
        "        [\"**/*box*out*.csv\", \"**/*Box_Out*.csv\", \"**/*Box Out*.csv\"],\n",
        "        prefer_tokens=prefer_2425\n",
        "    )\n",
        "\n",
        "    hustle_path = find_best(\n",
        "        [\"**/*hustle*.csv\", \"**/*Hustle*.csv\"],\n",
        "        prefer_tokens=prefer_2425\n",
        "    )\n",
        "\n",
        "    general_path = find_best(\n",
        "        [\"**/General*.csv\", \"**/*general*.csv\"],\n",
        "        prefer_tokens=prefer_2425,\n",
        "        require_tokens=[\"general\"]\n",
        "    )\n",
        "\n",
        "    # Shot selection (prefer 24-25, avoid 2016)\n",
        "    shot_fg_path = find_best(\n",
        "        [\"**/*Shot*Selection*.csv\", \"**/*Field*Goals*.csv\", \"**/*Attempts*.csv\"],\n",
        "        prefer_tokens=prefer_2425\n",
        "    )\n",
        "\n",
        "    log(\"\\nUsing files (FOR TRAINING):\")\n",
        "    log(f\" injury     = {injury_path}\")\n",
        "    log(f\" box_out    = {box_path}\")\n",
        "    log(f\" hustle     = {hustle_path}\")\n",
        "    log(f\" general    = {general_path}\")\n",
        "    log(f\" shot_sel   = {shot_fg_path}\")\n",
        "\n",
        "    # Load tables\n",
        "    def load_basic(path):\n",
        "        if not path:\n",
        "            return None\n",
        "        df = safe_read_csv(path)\n",
        "        df = ensure_player_col(df, os.path.basename(path))\n",
        "        if df is None:\n",
        "            return None\n",
        "        df = ensure_team_col(df)\n",
        "        df = make_unique_columns(df)\n",
        "        return collapse_traded_players(df, weight_col=\"GP\" if \"GP\" in df.columns else \"G\")\n",
        "\n",
        "    box = load_basic(box_path)\n",
        "    hustle = load_basic(hustle_path)\n",
        "    gen = load_basic(general_path)\n",
        "\n",
        "    # Shot selection can be in either \"header row first row\" format or normal\n",
        "    shot_fg = parse_shot_fg_safe(shot_fg_path) if shot_fg_path else None\n",
        "    if shot_fg is None and shot_fg_path:\n",
        "        # fallback: treat as a normal csv\n",
        "        shot_fg = load_basic(shot_fg_path)\n",
        "\n",
        "    if shot_fg is not None:\n",
        "        shot_fg = collapse_traded_players(shot_fg, weight_col=\"GP\" if \"GP\" in shot_fg.columns else \"G\")\n",
        "\n",
        "    # Merge available tables\n",
        "    stat_tables = [t for t in [box, hustle, gen, shot_fg] if t is not None]\n",
        "    if not stat_tables:\n",
        "        log(\"[warn] No stat tables loaded. Nothing to do.\")\n",
        "        return\n",
        "\n",
        "    df = make_unique_columns(stat_tables[0])\n",
        "    for nxt in stat_tables[1:]:\n",
        "        nxt = make_unique_columns(nxt)\n",
        "        df = df.merge(nxt, on=\"Player\", how=\"outer\", suffixes=(\"\", \"_DUP\"))\n",
        "        df = make_unique_columns(df)\n",
        "\n",
        "    # Player key\n",
        "    df[\"PLAYER_KEY\"] = canonical_name_series(df[\"Player\"])\n",
        "\n",
        "    # Injury scores\n",
        "    inj_scores = load_injury_scores_safe(injury_path) if injury_path else pd.DataFrame(\n",
        "        columns=[\"PLAYER_KEY\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"]\n",
        "    )\n",
        "\n",
        "    df = df.merge(inj_scores, on=\"PLAYER_KEY\", how=\"left\")\n",
        "    for c in [\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"]:\n",
        "        if c not in df.columns:\n",
        "            df[c] = 0\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
        "\n",
        "    # Target\n",
        "    y = np.log1p(df[\"INJURY_SCORE\"].values.astype(float))\n",
        "\n",
        "    # Features\n",
        "    exclude = {\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"}\n",
        "    feature_cols = []\n",
        "    X = df.copy()\n",
        "\n",
        "    for c in list(X.columns):\n",
        "        if c in [\"Player\",\"PLAYER_KEY\"] or c in exclude:\n",
        "            continue\n",
        "\n",
        "        col = X[c]\n",
        "        if isinstance(col, pd.DataFrame):\n",
        "            col = col.iloc[:, 0]\n",
        "            X[c] = col\n",
        "\n",
        "        if not pd.api.types.is_numeric_dtype(col):\n",
        "            coerced = pd.to_numeric(col, errors=\"coerce\")\n",
        "            if coerced.notna().sum() > 0:\n",
        "                X[c] = coerced\n",
        "                col = X[c]\n",
        "\n",
        "        if pd.api.types.is_numeric_dtype(col):\n",
        "            feature_cols.append(c)\n",
        "\n",
        "    if not feature_cols:\n",
        "        log(\"[warn] No numeric features found. Saving merged dataset for inspection.\")\n",
        "        df.to_csv(\"player_season_24_25_with_injury_score.csv\", index=False)\n",
        "        log(\"Saved: player_season_24_25_with_injury_score.csv\")\n",
        "        return\n",
        "\n",
        "    X = X[feature_cols]\n",
        "\n",
        "    # Model\n",
        "    model = Pipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"reg\", HistGradientBoostingRegressor(\n",
        "            max_depth=3, learning_rate=0.06, max_iter=400, random_state=42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # CV predictions\n",
        "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    preds = np.zeros(len(df))\n",
        "    for tr, te in cv.split(X):\n",
        "        model.fit(X.iloc[tr], y[tr])\n",
        "        preds[te] = model.predict(X.iloc[te])\n",
        "\n",
        "    pred_score = np.expm1(preds)\n",
        "    true_score = df[\"INJURY_SCORE\"].values.astype(float)\n",
        "\n",
        "    log(\"\\nRanking evaluation (predicting injury burden):\")\n",
        "    if HAVE_SCIPY:\n",
        "        rho, pval = spearmanr(pred_score, true_score)\n",
        "        log(f\" Spearman rho(pred, true injury_score): {rho:.4f} (p={pval:.2e})\")\n",
        "\n",
        "    k = max(1, int(0.10 * len(true_score)))\n",
        "    top_idx = np.argsort(-pred_score)[:k]\n",
        "    lift = true_score[top_idx].mean() / (true_score.mean() + 1e-9)\n",
        "    log(f\" Top 10% avg injury_score: {true_score[top_idx].mean():.3f}\")\n",
        "    log(f\" Overall avg injury_score: {true_score.mean():.3f}\")\n",
        "    log(f\" Top-10% lift: {lift:.3f}x\")\n",
        "\n",
        "    for thr in [1, 3, 5, 8]:\n",
        "        y_bin = (true_score >= thr).astype(int)\n",
        "        if y_bin.sum() < 10 or y_bin.sum() > len(y_bin) - 10:\n",
        "            continue\n",
        "        auc = roc_auc_score(y_bin, pred_score)\n",
        "        log(f\" AUC for injury_score >= {thr}: {auc:.4f} (positives={int(y_bin.sum())})\")\n",
        "\n",
        "    # Save outputs\n",
        "    out = df.copy()\n",
        "    out[\"PRED_INJURY_SCORE\"] = pred_score\n",
        "    out[\"PRED_INJURY_RANK\"] = out[\"PRED_INJURY_SCORE\"].rank(ascending=False, method=\"min\").astype(int)\n",
        "\n",
        "    out.to_csv(\"player_season_24_25_with_injury_score.csv\", index=False)\n",
        "    out[[\"Player\",\"PRED_INJURY_SCORE\",\"PRED_INJURY_RANK\",\"INJURY_SCORE\",\"UNIQUE_INJURY_DAYS\",\"INJURY_REPORT_ENTRIES\"]] \\\n",
        "        .sort_values(\"PRED_INJURY_RANK\") \\\n",
        "        .to_csv(\"player_injury_risk_scores_24_25.csv\", index=False)\n",
        "\n",
        "    log(\"\\nSaved:\")\n",
        "    log(\" player_season_24_25_with_injury_score.csv\")\n",
        "    log(\" player_injury_risk_scores_24_25.csv\")\n",
        "\n",
        "    # After the CV loop, retrain on ALL data\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Save the model\n",
        "    with open('injury_model.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    # Also save feature names for reference\n",
        "    with open('feature_cols.pkl', 'wb') as f:\n",
        "        pickle.dump(feature_cols, f)\n",
        "\n",
        "    log(\"Saved model to: injury_model.pkl\")\n",
        "    log(\"Saved features to: feature_cols.pkl\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-lMO_n0t6sNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20706892-ef76-4063-e464-fb6dd2cc7b2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "df = pd.read_csv(\"player_season_24_25_with_injury_score.csv\")\n",
        "\n",
        "y = df[\"INJURY_SCORE\"].values.astype(float)\n",
        "\n",
        "groups = {\n",
        "    \"Exposure\": [c for c in df.columns if c.lower() in [\"age\", \"gp\", \"min\", \"minutes\"]],\n",
        "\n",
        "    \"Shooting Profile\": [c for c in df.columns if (\n",
        "        \"FG\" in c or \"FGA\" in c or \"_FREQ\" in c or \"_FGA\" in c\n",
        "    )],\n",
        "\n",
        "    \"Hustle\": [c for c in df.columns if any(\n",
        "        k in c.lower() for k in [\"hustle\", \"deflect\", \"loose\", \"charge\", \"contest\"]\n",
        "    )],\n",
        "\n",
        "    \"Box Outs\": [c for c in df.columns if \"box\" in c.lower()],\n",
        "\n",
        "    \"Drives\": [c for c in df.columns if \"drive\" in c.lower()],\n",
        "}\n",
        "\n",
        "rows = []\n",
        "\n",
        "for gname, cols in groups.items():\n",
        "    cols = [c for c in cols if c in df.columns]\n",
        "    if not cols:\n",
        "        continue\n",
        "\n",
        "    Xg = df[cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "\n",
        "    # ðŸ”‘ key change: aggregate FIRST, then rank\n",
        "    group_sum = Xg.sum(axis=1)\n",
        "\n",
        "    # if still constant, skip\n",
        "    if group_sum.nunique() <= 1:\n",
        "        continue\n",
        "\n",
        "    group_signal = group_sum.rank(pct=True)\n",
        "\n",
        "    rho, _ = spearmanr(group_signal, y)\n",
        "\n",
        "    rows.append({\n",
        "        \"group\": gname,\n",
        "        \"spearman_rho_with_injury\": rho,\n",
        "        \"abs_rho\": abs(rho),\n",
        "        \"n_features_used\": len(cols)\n",
        "    })\n",
        "\n",
        "result = (\n",
        "    pd.DataFrame(rows)\n",
        "    .sort_values(\"abs_rho\", ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(\"\\nGroups most associated with injury burden (Spearman rho):\\n\")\n",
        "display(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "c2WuYlcwKYCz",
        "outputId": "c3f358e2-c82f-4e38-f761-cb29e8690c78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Groups most associated with injury burden (Spearman rho):\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              group  spearman_rho_with_injury   abs_rho  n_features_used\n",
              "0          Exposure                  0.543839  0.543839                4\n",
              "1            Hustle                  0.514442  0.514442               10\n",
              "2          Box Outs                  0.504578  0.504578                9\n",
              "3  Shooting Profile                  0.484031  0.484031                4\n",
              "4            Drives                  0.464235  0.464235                1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a650511-30b4-4396-be30-1dd2fa3003da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>spearman_rho_with_injury</th>\n",
              "      <th>abs_rho</th>\n",
              "      <th>n_features_used</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Exposure</td>\n",
              "      <td>0.543839</td>\n",
              "      <td>0.543839</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hustle</td>\n",
              "      <td>0.514442</td>\n",
              "      <td>0.514442</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Box Outs</td>\n",
              "      <td>0.504578</td>\n",
              "      <td>0.504578</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shooting Profile</td>\n",
              "      <td>0.484031</td>\n",
              "      <td>0.484031</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Drives</td>\n",
              "      <td>0.464235</td>\n",
              "      <td>0.464235</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a650511-30b4-4396-be30-1dd2fa3003da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a650511-30b4-4396-be30-1dd2fa3003da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a650511-30b4-4396-be30-1dd2fa3003da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4816c4e6-bccd-42d2-a039-ca91bf74da0d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4816c4e6-bccd-42d2-a039-ca91bf74da0d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Hustle\",\n          \"Drives\",\n          \"Box Outs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spearman_rho_with_injury\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030252453926437214,\n        \"min\": 0.4642346926309149,\n        \"max\": 0.5438394501824788,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5144415149460528,\n          0.4642346926309149,\n          0.5045782530696175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abs_rho\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030252453926437214,\n        \"min\": 0.4642346926309149,\n        \"max\": 0.5438394501824788,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5144415149460528,\n          0.4642346926309149,\n          0.5045782530696175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_features_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          10,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# 1. Load data\n",
        "df = pd.read_csv(\"player_season_24_25_with_injury_score.csv\")\n",
        "\n",
        "# 2. Ensure the target exists and is numeric\n",
        "if \"INJURY_SCORE\" not in df.columns:\n",
        "    print(\"Error: 'INJURY_SCORE' not found in CSV. Check your first script's output.\")\n",
        "else:\n",
        "    y = pd.to_numeric(df[\"INJURY_SCORE\"], errors=\"coerce\").fillna(0).values\n",
        "\n",
        "    exclude = {\n",
        "        \"Player\", \"PLAYER_KEY\", \"INJURY_SCORE\", \"UNIQUE_INJURY_DAYS\",\n",
        "        \"INJURY_REPORT_ENTRIES\", \"PRED_INJURY_SCORE\", \"PRED_INJURY_RANK\"\n",
        "    }\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in exclude:\n",
        "            continue\n",
        "\n",
        "        # Force numeric conversion\n",
        "        s = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "        # Skip if all NaN or if it's a constant value (0 variance)\n",
        "        if s.isna().all() or s.nunique(dropna=True) <= 1:\n",
        "            continue\n",
        "\n",
        "        # Fill NaNs for the correlation calculation\n",
        "        s_filled = s.fillna(0)\n",
        "\n",
        "        # Calculate Spearman Rho\n",
        "        rho, pval = spearmanr(s_filled, y)\n",
        "\n",
        "        if not np.isnan(rho):\n",
        "            rows.append({\n",
        "                \"stat\": col,\n",
        "                \"spearman_rho_with_injury\": rho,\n",
        "                \"abs_rho\": abs(rho),\n",
        "                \"p_value\": pval\n",
        "            })\n",
        "\n",
        "    # 3. Check if we actually found anything before sorting\n",
        "    if len(rows) > 0:\n",
        "        result = pd.DataFrame(rows)\n",
        "        result = result.sort_values(\"abs_rho\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "        print(\"\\nIndividual stats most associated with injury burden (Spearman rho):\\n\")\n",
        "        # Using print(result.head()) for standard scripts, display() for notebooks\n",
        "        print(result.head(30))\n",
        "    else:\n",
        "        print(\"No valid numeric columns found to correlate! Check if your CSV contains numeric data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JMLXvA7Lol3",
        "outputId": "747fe3a9-388b-4092-a82c-0a2496831ebe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Individual stats most associated with injury burden (Spearman rho):\n",
            "\n",
            "                           stat  spearman_rho_with_injury   abs_rho  \\\n",
            "0                           Min                  0.653165  0.653165   \n",
            "1                            GP                  0.561377  0.561377   \n",
            "2                  DEF Box Outs                  0.537712  0.537712   \n",
            "3          Team Reb On Box Outs                  0.533847  0.533847   \n",
            "4                      Box Outs                  0.533595  0.533595   \n",
            "5                       Min_DUP                  0.531561  0.531561   \n",
            "6           Contested 3PT Shots                  0.492954  0.492954   \n",
            "7   PCT Player Reb When Box Out                  0.490849  0.490849   \n",
            "8                        GP_DUP                  0.485480  0.485480   \n",
            "9     PCT Team Reb When Box Out                  0.485321  0.485321   \n",
            "10                      FGA_DUP                  0.480278  0.480278   \n",
            "11             PCT Box Outs Def                  0.478217  0.478217   \n",
            "12               Contested Shot                  0.477764  0.477764   \n",
            "13       Player Reb On Box Outs                  0.474802  0.474802   \n",
            "14                          PTS                  0.470922  0.470922   \n",
            "15                          MIN                  0.467723  0.467723   \n",
            "16                          FGA                  0.464760  0.464760   \n",
            "17                          FTM                  0.464275  0.464275   \n",
            "18                       DRIVES                  0.464235  0.464235   \n",
            "19                          FGM                  0.463729  0.463729   \n",
            "20                          FTA                  0.462304  0.462304   \n",
            "21                           PF                  0.461276  0.461276   \n",
            "22                  Deflections                  0.460816  0.460816   \n",
            "23        Loose Balls Recovered                  0.459814  0.459814   \n",
            "24                          Age                  0.459739  0.459739   \n",
            "25    DEF Loose Balls Recovered                  0.452219  0.452219   \n",
            "26                           TO                  0.447969  0.447969   \n",
            "27                   Age_DUP__2                  0.442447  0.442447   \n",
            "28    OFF Loose Balls Recovered                  0.441745  0.441745   \n",
            "29                         PASS                  0.441459  0.441459   \n",
            "\n",
            "         p_value  \n",
            "0   4.078652e-94  \n",
            "1   1.184483e-64  \n",
            "2   1.819195e-58  \n",
            "3   1.675665e-57  \n",
            "4   1.935646e-57  \n",
            "5   6.150824e-57  \n",
            "6   5.023970e-48  \n",
            "7   1.428236e-47  \n",
            "8   1.987899e-46  \n",
            "9   2.147545e-46  \n",
            "10  2.437854e-45  \n",
            "11  6.504598e-45  \n",
            "12  8.061378e-45  \n",
            "13  3.258548e-44  \n",
            "14  1.988644e-43  \n",
            "15  8.683143e-43  \n",
            "16  3.353541e-42  \n",
            "17  4.178937e-42  \n",
            "18  4.256271e-42  \n",
            "19  5.350769e-42  \n",
            "20  1.017998e-41  \n",
            "21  1.615697e-41  \n",
            "22  1.985607e-41  \n",
            "23  3.108120e-41  \n",
            "24  3.214155e-41  \n",
            "25  8.846217e-40  \n",
            "26  5.555057e-39  \n",
            "27  5.818207e-38  \n",
            "28  7.816550e-38  \n",
            "29  8.817659e-38  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load model and training features\n",
        "with open('injury_model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "with open('feature_cols.pkl', 'rb') as f:\n",
        "    training_feature_cols = pickle.load(f)\n",
        "\n",
        "print(f\"Model was trained on these {len(training_feature_cols)} features:\")\n",
        "print(training_feature_cols)\n",
        "\n",
        "# Prepare your 2016-17 data\n",
        "current_files = [\n",
        "    \"test/2016-17_Box Out.csv\",\n",
        "    \"test/2016-17_Hustle Stats.csv\",\n",
        "    \"test/2016-17_Shot Selection.csv\",\n",
        "    \"test/2016-17_Tracking.csv\"\n",
        "]\n",
        "\n",
        "new_season_data = prepare_new_data(current_files)\n",
        "\n",
        "# Extract feature columns from new data (as before)\n",
        "exclude = {\"INJURY_SCORE\", \"UNIQUE_INJURY_DAYS\", \"INJURY_REPORT_ENTRIES\",\n",
        "           \"PRED_INJURY_SCORE\", \"PRED_INJURY_RANK\"}\n",
        "available_features = []\n",
        "X_temp = new_season_data.copy()\n",
        "\n",
        "for c in list(X_temp.columns):\n",
        "    if c in [\"Player\", \"PLAYER_KEY\"] or c in exclude:\n",
        "        continue\n",
        "\n",
        "    col = X_temp[c]\n",
        "    if isinstance(col, pd.DataFrame):\n",
        "        col = col.iloc[:, 0]\n",
        "        X_temp[c] = col\n",
        "\n",
        "    if not pd.api.types.is_numeric_dtype(col):\n",
        "        coerced = pd.to_numeric(col, errors=\"coerce\")\n",
        "        if coerced.notna().sum() > 0:\n",
        "            X_temp[c] = coerced\n",
        "            col = X_temp[c]\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(col):\n",
        "        available_features.append(c)\n",
        "\n",
        "print(f\"\\nAvailable features in 2016-17 data: {len(available_features)}\")\n",
        "\n",
        "# KEY FIX: Create a dataframe with ALL training features, filling missing ones with 0\n",
        "X_new = pd.DataFrame(index=X_temp.index)\n",
        "\n",
        "for feature in training_feature_cols:\n",
        "    if feature in available_features:\n",
        "        X_new[feature] = X_temp[feature]\n",
        "    else:\n",
        "        print(f\"Warning: Feature '{feature}' not found in test data. Filling with 0.\")\n",
        "        X_new[feature] = 0\n",
        "\n",
        "# Now ensure the column order matches exactly\n",
        "X_new = X_new[training_feature_cols]\n",
        "\n",
        "print(f\"\\nFinal X_new shape: {X_new.shape}\")\n",
        "print(f\"Expected shape: ({len(X_temp)}, {len(training_feature_cols)})\")\n",
        "\n",
        "# Generate predictions\n",
        "log_predictions = model.predict(X_new)\n",
        "new_season_data[\"PREDICTED_INJURY_SCORE\"] = np.expm1(log_predictions)\n",
        "\n",
        "# Create leaderboard\n",
        "leaderboard = new_season_data[[\"Player\", \"PREDICTED_INJURY_SCORE\"]].sort_values(\n",
        "    \"PREDICTED_INJURY_SCORE\", ascending=False\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Top 10 Players at Risk (2016-17 Stats):\")\n",
        "print(\"=\"*60)\n",
        "print(leaderboard.head(10).to_string(index=False))\n",
        "\n",
        "# Save results\n",
        "leaderboard.to_csv(\"2016_17_injury_predictions.csv\", index=False)\n",
        "print(\"\\nSaved predictions to: 2016_17_injury_predictions.csv\")"
      ],
      "metadata": {
        "id": "GgccozBWsiri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248eba69-1161-4ad3-cd64-3aa5066e0978"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained on these 50 features:\n",
            "['Age', 'GP', 'Min', 'Box Outs', 'OFF Box Outs', 'DEF Box Outs', 'Team Reb On Box Outs', 'Player Reb On Box Outs', 'PCT Box Outs Off', 'PCT Box Outs Def', 'PCT Team Reb When Box Out', 'PCT Player Reb When Box Out', 'Age_DUP', 'GP_DUP', 'Min_DUP', 'Screen Assists', 'Screen Assists PTS', 'Deflections', 'OFF Loose Balls Recovered', 'DEF Loose Balls Recovered', 'Loose Balls Recovered', 'PCT Loose Balls Recovered OFF', 'PCT Loose Balls Recovered DEF', 'Charges Drawn', 'Contested 2PT Shots', 'Contested 3PT Shots', 'Contested Shot', 'GP_DUP__2', 'W', 'L', 'MIN', 'DRIVES', 'FGM', 'FGA', 'FGPCT', 'FTM', 'FTA', 'FTPCT', 'PTS', 'PTSPCT', 'PASS', 'PASSPCT', 'AST', 'ASTPCT', 'TO', 'TOVPCT', 'PF', 'PFPCT', 'Age_DUP__2', 'FGA_DUP']\n",
            "\n",
            "Available features in 2016-17 data: 56\n",
            "Warning: Feature 'Contested Shot' not found in test data. Filling with 0.\n",
            "\n",
            "Final X_new shape: (1013, 50)\n",
            "Expected shape: (1013, 50)\n",
            "\n",
            "============================================================\n",
            "Top 10 Players at Risk (2016-17 Stats):\n",
            "============================================================\n",
            "          Player  PREDICTED_INJURY_SCORE\n",
            "Jimmy Butler III               48.586886\n",
            "D'Angelo Russell               34.770633\n",
            "   Anthony Davis               26.289029\n",
            " Dennis SchrÃ¶der               23.536337\n",
            "   Kawhi Leonard               23.099471\n",
            "      Kevin Love               22.995435\n",
            "     Joel Embiid               22.689665\n",
            "    Nikola JokiÄ‡               22.521985\n",
            "    Nikola JokiÄ‡               22.521985\n",
            "     Paul George               22.357158\n",
            "\n",
            "Saved predictions to: 2016_17_injury_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}